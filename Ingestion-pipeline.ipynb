{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2171f048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ngunupud\\Desktop\\Toy_Agent\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852b5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pinecone module file: c:\\Users\\ngunupud\\Desktop\\Toy_Agent\\.venv\\Lib\\site-packages\\pinecone\\__init__.py\n",
      "pinecone contents sample: ['ByocSpec', 'Pinecone', 'PineconeApiAttributeError', 'PineconeApiException', 'PineconeApiKeyError', 'PineconeApiTypeError', 'PineconeApiValueError', 'PineconeAsyncio', 'PineconeConfig', 'PineconeConfigurationError', 'PineconeException', 'PineconeProtocolError', 'PodSpec', 'PodSpecDefinition', 'ServerlessSpec', 'ServerlessSpecDefinition']\n"
     ]
    }
   ],
   "source": [
    "import pinecone, inspect\n",
    "print(\"pinecone module file:\", getattr(pinecone, \"__file__\", None))\n",
    "print(\"pinecone contents sample:\", [x for x in dir(pinecone) if \"Pine\" in x or \"Spec\" in x][:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8dd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, hashlib\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pypdf import PdfReader\n",
    "from docx import Document\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3473c6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Key detected (length): 75\n",
      "✅ DATA_DIR exists: True C:\\Users\\ngunupud\\Desktop\\Toy_Agent\\realistic_docs_hr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./realistic_docs_hr\")\n",
    "INDEX_NAME = \"test-agent\"\n",
    "NAMESPACE = \"toy-agent\"\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "assert PINECONE_API_KEY, \"Set env var PINECONE_API_KEY first\"\n",
    "\n",
    "print(\"✅ Key detected (length):\", len(PINECONE_API_KEY))\n",
    "print(\"✅ DATA_DIR exists:\", DATA_DIR.exists(), DATA_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9820ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected. Indexes: ['test-agent']\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"✅ Connected. Indexes:\", pc.list_indexes().names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48f43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using existing index: test-agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ngunupud\\Desktop\\Toy_Agent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "existing = pc.list_indexes().names()\n",
    "\n",
    "if INDEX_NAME not in existing:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=1024,      # must match llama-text-embed-v2 output for your setup\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(\"✅ Created index:\", INDEX_NAME)\n",
    "else:\n",
    "    print(\"✅ Using existing index:\", INDEX_NAME)\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185b1f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found files: 15\n",
      "✅ Example file: HR-001_Code_of_Conduct.pdf\n"
     ]
    }
   ],
   "source": [
    "files = sorted([*DATA_DIR.glob(\"*.pdf\"), *DATA_DIR.glob(\"*.docx\"), *DATA_DIR.glob(\"*.rtf\")])\n",
    "print(\"✅ Found files:\", len(files))\n",
    "print(\"✅ Example file:\", files[0].name if files else \"NONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc73e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ load_file ready\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    text = text.replace(\"\\x00\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def sha256_text(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "def load_pdf_text(path: Path) -> str:\n",
    "    reader = PdfReader(str(path))\n",
    "    return \"\\n\".join([(p.extract_text() or \"\") for p in reader.pages])\n",
    "\n",
    "def load_docx_text(path: Path) -> str:\n",
    "    doc = Document(str(path))\n",
    "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text])\n",
    "\n",
    "def load_rtf_text(path: Path) -> str:\n",
    "    raw = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    return rtf_to_text(raw)\n",
    "\n",
    "def infer_doc_id_from_filename(name: str) -> str:\n",
    "    m = re.search(r\"(HR-\\d{3})\", name)\n",
    "    return m.group(1) if m else name.split(\"_\")[0]\n",
    "\n",
    "def load_file(path: Path) -> Tuple[str, Dict[str, Any]]:\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".pdf\":\n",
    "        text, source_type = load_pdf_text(path), \"pdf\"\n",
    "    elif ext == \".docx\":\n",
    "        text, source_type = load_docx_text(path), \"docx\"\n",
    "    elif ext == \".rtf\":\n",
    "        text, source_type = load_rtf_text(path), \"rtf\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "    text = normalize_text(text)\n",
    "    meta = {\n",
    "        \"doc_id\": infer_doc_id_from_filename(path.name),\n",
    "        \"file_name\": path.name,\n",
    "        \"source_type\": source_type,\n",
    "        \"doc_hash\": sha256_text(text),\n",
    "        \"text_len\": len(text),\n",
    "    }\n",
    "    return text, meta\n",
    "\n",
    "print(\"✅ load_file ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a3a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 15/15 [00:00<00:00, 79.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded docs: 15\n",
      "✅ Example meta: {'doc_id': 'HR-001', 'file_name': 'HR-001_Code_of_Conduct.pdf', 'source_type': 'pdf', 'doc_hash': '6d4c86134330795833509f87d3feae03edc308b3346146d3306e6409b371cebc', 'text_len': 1435}\n",
      "✅ Preview: Document ID: HR-001 Topic: HR Policies Title: Code of Conduct Version: 1.2 Author: K. Patel Department: HR Operations Effective Date: 2025-12-28 1. Purpose This policy defines expectations and procedu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for fp in tqdm(files, desc=\"Loading files\"):\n",
    "    text, meta = load_file(fp)\n",
    "    if len(text) < 50:\n",
    "        continue\n",
    "    docs.append({\"text\": text, \"meta\": meta})\n",
    "\n",
    "print(\"✅ Loaded docs:\", len(docs))\n",
    "print(\"✅ Example meta:\", docs[0][\"meta\"])\n",
    "print(\"✅ Preview:\", docs[0][\"text\"][:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f12f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total chunks: 30\n",
      "✅ Sample chunk id: HR-001__0000__47e77d311b\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text: str, max_chars: int = 900, overlap: int = 150) -> List[str]:\n",
    "    text = normalize_text(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(text)\n",
    "\n",
    "    while start < n:\n",
    "        end = min(n, start + max_chars)\n",
    "        c = text[start:end].strip()\n",
    "        if c:\n",
    "            chunks.append(c)\n",
    "\n",
    "        if end == n:\n",
    "            break\n",
    "        start = max(0, end - overlap)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = []\n",
    "for d in docs:\n",
    "    meta = d[\"meta\"]\n",
    "    doc_id = meta[\"doc_id\"]\n",
    "\n",
    "    for idx, ch in enumerate(chunk_text(d[\"text\"], max_chars=900, overlap=150)):\n",
    "        if len(ch) < 50:\n",
    "            continue\n",
    "\n",
    "        chunk_id = f\"{doc_id}__{idx:04d}__{sha256_text(ch)[:10]}\"\n",
    "        chunks.append({\n",
    "            \"id\": chunk_id,\n",
    "            \"text\": ch,\n",
    "            \"doc_id\": doc_id,\n",
    "            \"chunk_index\": idx,\n",
    "            \"file_name\": meta[\"file_name\"],\n",
    "            \"source_type\": meta[\"source_type\"],\n",
    "        })\n",
    "\n",
    "print(\"✅ Total chunks:\", len(chunks))\n",
    "print(\"✅ Sample chunk id:\", chunks[0][\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faad3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embed+Upsert: 100%|██████████| 1/1 [00:09<00:00,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted vectors: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH = 32\n",
    "\n",
    "def batched(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i+n]\n",
    "\n",
    "total = 0\n",
    "\n",
    "for batch in tqdm(list(batched(chunks, BATCH)), desc=\"Embed+Upsert\"):\n",
    "    # ---- EMBEDDING happens here (Pinecone-hosted model) ----\n",
    "    embedded = pc.inference.embed(\n",
    "        model=\"llama-text-embed-v2\",\n",
    "        inputs=[b[\"text\"] for b in batch],\n",
    "        parameters={\"input_type\": \"passage\"}\n",
    "    )\n",
    "\n",
    "    vectors = [e.values for e in embedded.data]\n",
    "\n",
    "    to_upsert = []\n",
    "    for b, vec in zip(batch, vectors):\n",
    "        meta = {\n",
    "            \"doc_id\": b[\"doc_id\"],\n",
    "            \"chunk_index\": b[\"chunk_index\"],\n",
    "            \"text\": b[\"text\"],\n",
    "            \"file_name\": b[\"file_name\"],\n",
    "            \"source_type\": b[\"source_type\"],\n",
    "        }\n",
    "        to_upsert.append((b[\"id\"], vec, meta))\n",
    "\n",
    "    index.upsert(vectors=to_upsert, namespace=NAMESPACE)\n",
    "    total += len(to_upsert)\n",
    "\n",
    "print(\"✅ Upserted vectors:\", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b029bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.310680151 HR-004 HR-004_Remote_Work_Policy.pdf\n",
      "   Document ID: HR-004 Topic: HR Policies Title: Remote Work Policy Version: 1.5 Author: J. Smith Department: Talent Acquis\n",
      "0.270581543 HR-002 HR-002_Attendance_and_Punctuality.pdf\n",
      "   Document ID: HR-002 Topic: HR Policies Title: Attendance and Punctuality Version: 1.7 Author: S. Ahmed Department: Peopl\n",
      "0.25663358 HR-013 HR-013_Training_and_Development.docx\n",
      "   Document ID: HR-013 Topic: HR Policies Title: Training and Development Version: 1.3 Author: A. Rao Department: HRBP Effe\n"
     ]
    }
   ],
   "source": [
    "q = \"What is the purpose of this policy?\"\n",
    "q_emb = pc.inference.embed(\n",
    "    model=\"llama-text-embed-v2\",\n",
    "    inputs=[q],\n",
    "    parameters={\"input_type\": \"query\"}\n",
    ")\n",
    "\n",
    "res = index.query(\n",
    "    vector=q_emb.data[0].values,\n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    namespace=NAMESPACE\n",
    ")\n",
    "\n",
    "for m in res[\"matches\"]:\n",
    "    md = m[\"metadata\"]\n",
    "    print(m[\"score\"], md.get(\"doc_id\"), md.get(\"file_name\"))\n",
    "    print(\"  \", md.get(\"text\", \"\")[:120])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16d6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI client ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"XXXX\"\n",
    "\n",
    "openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "print(\"✅ OpenAI client ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bf5be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(matches, max_chars: int = 6000) -> str:\n",
    "    parts = []\n",
    "    used = 0\n",
    "\n",
    "    for m in matches:\n",
    "        md = m.get(\"metadata\") or {}\n",
    "        text = md.get(\"text\") or \"\"\n",
    "        doc_id = md.get(\"doc_id\")\n",
    "        file_name = md.get(\"file_name\")\n",
    "\n",
    "        header = f\"[doc_id={doc_id} file={file_name}]\"\n",
    "        snippet = text[:1200]  # keep each chunk limited\n",
    "        block = header + \"\\n\" + snippet\n",
    "\n",
    "        if used + len(block) > max_chars:\n",
    "            break\n",
    "\n",
    "        parts.append(block)\n",
    "        used += len(block)\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2f61a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query: str, top_k: int = 5) -> str:\n",
    "    # 1) Embed query with Pinecone-hosted embedding model\n",
    "    q_emb = pc.inference.embed(\n",
    "        model=\"llama-text-embed-v2\",\n",
    "        inputs=[query],\n",
    "        parameters={\"input_type\": \"query\"}\n",
    "    )\n",
    "\n",
    "    # 2) Retrieve similar chunks from Pinecone\n",
    "    res = index.query(\n",
    "        vector=q_emb.data[0].values,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=NAMESPACE\n",
    "    )\n",
    "\n",
    "    matches = res.get(\"matches\", [])\n",
    "    if not matches:\n",
    "        return \"I couldn't find relevant information in the documents.\"\n",
    "\n",
    "    # 3) Build context\n",
    "    context = build_context(matches)\n",
    "\n",
    "    # 4) Generate answer with OpenAI\n",
    "    system = (\n",
    "        \"You are a helpful assistant for HR policy Q&A. \"\n",
    "        \"Use ONLY the provided context. \"\n",
    "        \"If the answer is not in the context, say: \"\n",
    "        \"\\\"I don't know based on the provided documents.\\\"\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    resp = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return resp.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05bc4b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Employee Onboarding\" policy defines expectations and procedures for onboarding within the organization. It applies to all employees, interns, contractors, and temporary staff. Employees must comply with the onboarding requirements, and non-compliance may result in corrective action.\n",
      "\n",
      "The procedure for onboarding includes:\n",
      "\n",
      "1. **Request / Initiation**: Requests must be submitted via the HR portal or an approved communication channel.\n",
      "2. **Review and Approval**: The employee's manager and HR Compliance must review requests where applicable.\n",
      "3. **Execution**: Approved actions are implemented within standard timelines; exceptions require documentation.\n",
      "4. **Recordkeeping**: HR maintains records according to retention guidelines.\n",
      "5. **Monitoring and Auditing**: HR performs periodic checks and may audit related activities for adherence.\n",
      "6. **Exceptions**: Exceptions require written approval from HR Compliance and the relevant department head.\n",
      "\n",
      "There are also FAQs and examples provided, such as how to initiate an onboarding-related request and what documentation is required. The policy was initially released on December 28, 2025, and is currently in version 1.7.\n"
     ]
    }
   ],
   "source": [
    "print(rag_answer(\"anything i can knw about Employee onboarding?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a6dc2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceptions require written approval from HR Compliance and the relevant department head.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa6a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
